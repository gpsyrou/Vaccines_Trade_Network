{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaccines Trade Network\n",
    "### Author: Georgios Spyrou\n",
    "### Date: 23/05/2020\n",
    "\n",
    "<img src=\"https://www.our-voices.org.uk/assets/images/Network-diagram.png\" width=720 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Puprose\n",
    "\n",
    "Scope of this project is to construct the global trade network of vaccines around the globe for multiple years(current data span from 2017 to 2019. Through plotting and statistical analysis, we want to identify informative patterns on how different countries change their import/export activity of vaccines. \n",
    "\n",
    "### Part 1: Data Retrieval\n",
    "\n",
    "In order to find and retrieve data we have utilised the UN Comtrade API (https://comtrade.un.org/Data/).This is a great place if someone wants to find data regarding exports/impors of countries around the world, pretty much for any product/service. The data are very well documented and visualized on the website, and it's easy to do some exploration  and locate data that seem interesting for your project.\n",
    "\n",
    "Therefore, after I managed to identify the relevant data that I wanted to work with (vaccines for human medicine), I had to find a way to leverage the API to get my data. Even though the website allows us to download sample CSV files, if we wanted to do that for multiple years and countries it would take a lot of time. Hence, I have decided to approach the data retrival from a Python standpoint, in order to automate this task.\n",
    "\n",
    "Before we jump to the part of how we are going to automate the data retrieval, it might worths it to explain what exactly we are aiming to retrieve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UN Comtrade database is giving us the opportunity to pick from a plethora of goods and services. My first task was to find the specific code that corresponds to human vaccines. After a bit of research we have found that this code is *300220*, which is a unique value that will allow us to only pick data for this good/product. After we located our product code, we have to decide on the time range that we want to pick data for. This can quickly get tricky as the database does not allow you to many years/countries all at once. But for now lets say that the scope of interest was *monthly* data from 2017 to 2019, for as many countries as possible - mainly because there are countries which do not seem to import/export vaccines or we do not have relevant information about them.\n",
    "\n",
    "Now that are know pretty much what we are looking for, lets dive into creating some API calls in Python to automatically get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Setting up the parameters for the API calls to receive the data\n",
    "\n",
    "max_rec = 100000\n",
    "output_fmt = 'csv'\n",
    "trade_type = 'C'            # Commodities\n",
    "frequency = 'M'             # Monthly\n",
    "px = 'HS'                   # Classification for products\n",
    "cc = 300220                 # Subcategory --> 300220 code for Vaccines\n",
    "reporter = 'all'\n",
    "partner = 'all'                 \n",
    "rg ='all'\n",
    "\n",
    "# Connection string to comtrade.un.org based on the parameters above\n",
    "api_call_string = f'http://comtrade.un.org/api/get?max={max_rec}&type={trade_type}&freq={frequency}&px={px}&ps=year&r=reporter&p={partner}&rg={rg}&cc={cc}&fmt={output_fmt}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have set up the string that will be used to do the appropriate API calls, it's time create a function that will use this string to retrieve the data and generate the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataCall(api_string: str, reporterid: str, reportername: str, year: int, out_folder: str) -> None:\n",
    "    '''\n",
    "    Create a .csv file that contains the data as received from  https://comtrade.un.org/Data/, for a specific year.\n",
    "\n",
    "    Args:\n",
    "    ----\n",
    "        api_string: String that contains the URL for the API call. The string already contains all the paremeters required for the call.\n",
    "        reporter: Specify Reporter country.\n",
    "        year: Specify year of interest.\n",
    "    Returns:\n",
    "    -------\n",
    "        None: The output is a .csv file that contains the data for a specified year.\n",
    "    '''\n",
    "    csv_by_year_out_loc = os.path.join(out_folder, f'{year}')\n",
    "    if not os.path.exists(csv_by_year_out_loc):\n",
    "        os.makedirs(name=csv_by_year_out_loc)\n",
    "\n",
    "    api_string = api_string.replace('year', f'{year}').replace('reporter', f'{reporterid}')\n",
    "    print(api_string)\n",
    "\n",
    "    response = requests.get(url=api_string)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print('Could not access the API!')\n",
    "    else:\n",
    "        decoded_data = response.content.decode('utf-8')\n",
    "        csv_file = csv.reader(decoded_data.splitlines())\n",
    "        datalines = list(csv_file)\n",
    "\n",
    "        with open(os.path.join(csv_by_year_out_loc, f'Comtrade_Vaccines_Data_{reportername}_{year}.csv'), 'w', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter=',')\n",
    "            writer.writerows(datalines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this call will run for *each* country, therefore we will end up with a lot of csv files. The country codes can be found here: https://comtrade.un.org/Data/cache/reporterAreas.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reporters_url = 'https://comtrade.un.org/Data/cache/partnerAreas.json'\n",
    "reporters_resp = requests.get(url=reporters_url)\n",
    "json_data = json.loads(reporters_resp.text)\n",
    "\n",
    "reporters_list = [rep for rep in json_data['results']]\n",
    "\n",
    "# Get the data as separate csv files, each for every year of interest\n",
    "years_ls = [2017]\n",
    "outputFilesFolder = f'CSVFiles\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for api_check, repd in enumerate(reporters_list):\n",
    "    # Need to make the script to sleep every 100 calls, as the API is blocking us for an hour for every 100 calls.\n",
    "    if api_check !=0 and api_check % 100 == 0:\n",
    "        time.sleep(3600)\n",
    "    countryname = repd['text']\n",
    "    c_id = repd['id']\n",
    "    print(f'\\nCountry..: {countryname}')\n",
    "    for year in years_ls:\n",
    "        print(f'\\nReceiving the data for {year} from https://comtrade.un.org/...\\n')\n",
    "        getDataCall(api_call_string, reporterid=c_id, reportername=countryname, year=year, out_folder=outputFilesFolder)\n",
    "        time.sleep(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have successfully get the data for every country that we cound find a corresponding country code. That said, as we mentioned before there are some countries that contain no data for a specific year - which is might be for many reasons but this is out of the scope of this project. Hence, after we have ended up with multiple csv files , one for each country , we can repeat this process for as many years as we want to. I have repeated it three times (2017, 2018, 2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can probably imagine this process generated over 300 csv files (3 years x over 100 countries). Hence it was necessary to perform some data cleaning operations in the directory that the files were created. The main task was to merge all this files for a specific year (e.g. all countries for 2017 merged to a common csv file), and at the same time delete all the files from the directory that contained no data.\n",
    "\n",
    "In order to do that we have created a script to automatically do this for us, but as it might not be that of an interesting task we are going to leave it outside of this notebook. That said, the code that completes this can be found here: https://github.com/gpsyrou/Vaccines_Trade_Network/blob/master/dataCleaning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploratory Data Analysis & Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data organized into separate csv files by year, we can start the task of exploring what we actually got from the data retriaval process. We will explore this by taking into consideration only the data received for 2018.\n",
    "\n",
    "**Note**: Frow now on you are going to see two packages, one named Functions and one named VaccinesTradeNetworkClass. Please note that these are custom packages that I have created for the purposes of this project. The first one contains some functions that we will keep using for our EDA tasks, while the VaccinesTradeNetworkClass one will be used later on, when we jump into creating out network graph objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\george\\\\Desktop\\\\GitHub\\\\Projects\\\\Comtrade_Network')\n",
    "year = 2018\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom packages\n",
    "from Functions import tradeNetworkFunctions as tnf\n",
    "from VaccinesTradeNetworkClass import VaccinesTradeNetwork\n",
    "\n",
    "# Plotting and graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "csv_file_location = f'C:\\\\Users\\\\george\\\\Desktop\\\\GitHub\\\\Projects\\\\Comtrade_Network\\\\Merged_CSVs\\\\Comtrade_Vacciness_Data_{year}'\n",
    "\n",
    "# Read the csv file\n",
    "maindf = pd.read_csv(csv_file_location, delimiter=',', header=[0], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage we need to explore the dataset and identify any potential issues in the data tha require cleaning, and also make sure that we understand the features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Period</th>\n",
       "      <th>Aggregate Level</th>\n",
       "      <th>Is Leaf Code</th>\n",
       "      <th>Trade Flow Code</th>\n",
       "      <th>Reporter Code</th>\n",
       "      <th>Reporter ISO</th>\n",
       "      <th>Partner Code</th>\n",
       "      <th>Partner ISO</th>\n",
       "      <th>2nd Partner Code</th>\n",
       "      <th>...</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Alt Qty Unit Code</th>\n",
       "      <th>Alt Qty Unit</th>\n",
       "      <th>Alt Qty</th>\n",
       "      <th>Netweight (kg)</th>\n",
       "      <th>Gross weight (kg)</th>\n",
       "      <th>Trade Value (US$)</th>\n",
       "      <th>CIF Trade Value (US$)</th>\n",
       "      <th>FOB Trade Value (US$)</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19054.0</td>\n",
       "      <td>19054.000000</td>\n",
       "      <td>19054.0</td>\n",
       "      <td>19054.0</td>\n",
       "      <td>19054.000000</td>\n",
       "      <td>19054.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19054.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.605100e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.905400e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>201806.537525</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.568122</td>\n",
       "      <td>447.424950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>390.799465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.557074e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.449306e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.426326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545859</td>\n",
       "      <td>268.986699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.520021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.289827e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.536633e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>201801.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>201804.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.364250e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>201807.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.700000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.340225e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>201810.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.861000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067766e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>201812.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>894.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.408547e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.452230e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year         Period  Aggregate Level  Is Leaf Code  Trade Flow Code  \\\n",
       "count  19054.0   19054.000000          19054.0       19054.0     19054.000000   \n",
       "mean    2018.0  201806.537525              6.0           1.0         1.568122   \n",
       "std        0.0       3.426326              0.0           0.0         0.545859   \n",
       "min     2018.0  201801.000000              6.0           1.0         1.000000   \n",
       "25%     2018.0  201804.000000              6.0           1.0         1.000000   \n",
       "50%     2018.0  201807.000000              6.0           1.0         2.000000   \n",
       "75%     2018.0  201810.000000              6.0           1.0         2.000000   \n",
       "max     2018.0  201812.000000              6.0           1.0         4.000000   \n",
       "\n",
       "       Reporter Code  Reporter ISO  Partner Code  Partner ISO  \\\n",
       "count   19054.000000           0.0  19054.000000          0.0   \n",
       "mean      447.424950           NaN    390.799465          NaN   \n",
       "std       268.986699           NaN    281.520021          NaN   \n",
       "min        24.000000           NaN      0.000000          NaN   \n",
       "25%       246.000000           NaN    124.000000          NaN   \n",
       "50%       410.000000           NaN    372.000000          NaN   \n",
       "75%       702.000000           NaN    682.000000          NaN   \n",
       "max       894.000000           NaN    899.000000          NaN   \n",
       "\n",
       "       2nd Partner Code   ...     Qty  Alt Qty Unit Code  Alt Qty Unit  \\\n",
       "count               0.0   ...     0.0                0.0           0.0   \n",
       "mean                NaN   ...     NaN                NaN           NaN   \n",
       "std                 NaN   ...     NaN                NaN           NaN   \n",
       "min                 NaN   ...     NaN                NaN           NaN   \n",
       "25%                 NaN   ...     NaN                NaN           NaN   \n",
       "50%                 NaN   ...     NaN                NaN           NaN   \n",
       "75%                 NaN   ...     NaN                NaN           NaN   \n",
       "max                 NaN   ...     NaN                NaN           NaN   \n",
       "\n",
       "       Alt Qty  Netweight (kg)  Gross weight (kg)  Trade Value (US$)  \\\n",
       "count      0.0    1.605100e+04                0.0       1.905400e+04   \n",
       "mean       NaN    6.557074e+03                NaN       5.449306e+06   \n",
       "std        NaN    7.289827e+04                NaN       3.536633e+07   \n",
       "min        NaN    0.000000e+00                NaN       0.000000e+00   \n",
       "25%        NaN    2.500000e+01                NaN       1.364250e+04   \n",
       "50%        NaN    2.700000e+02                NaN       1.340225e+05   \n",
       "75%        NaN    1.861000e+03                NaN       1.067766e+06   \n",
       "max        NaN    5.408547e+06                NaN       9.452230e+08   \n",
       "\n",
       "       CIF Trade Value (US$)  FOB Trade Value (US$)     Flag  \n",
       "count                    0.0                    0.0  19054.0  \n",
       "mean                     NaN                    NaN      0.0  \n",
       "std                      NaN                    NaN      0.0  \n",
       "min                      NaN                    NaN      0.0  \n",
       "25%                      NaN                    NaN      0.0  \n",
       "50%                      NaN                    NaN      0.0  \n",
       "75%                      NaN                    NaN      0.0  \n",
       "max                      NaN                    NaN      0.0  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = maindf.describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the summary, few of the features does not seem to provide useful information for our analysis, as they either contain only empty values (e.g. 'Qty') or they contain fixed values (e.g.'Aggregate Level'). Therefore we will exclude the useless columns from our dataset to reduce the noise and the dimensions of our feature space.\n",
    "\n",
    "Note: More information regarding the feautures can be found here: https://comtrade.un.org/data/MethodologyGuideforComtradePlus.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features_ls = ['Period', 'Reporter Code', 'Reporter', 'Partner Code',\n",
    "                      'Partner', 'Trade Flow', 'Commodity', 'Netweight (kg)',\n",
    "                      'Trade Value (US$)']\n",
    "df = maindf[useful_features_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Imports', 'Exports'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Trade Flow'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider both 'Re-imports' and 'Re-exports' as 'Imports' and 'Exports' respectively and we will drop the entries where we dont have info about the trade flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_flow_dict = {'Re-imports':'Imports', \n",
    "                   'Re-exports':'Exports',\n",
    "                   'Imports':'Imports', \n",
    "                   'Exports':'Exports'}\n",
    "\n",
    "df['Trade Flow'] = df['Trade Flow'].map(trade_flow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Portugal', 'India', 'France', 'World', 'United Kingdom',\n",
       "       'South Africa', 'Belgium', 'Denmark', 'Rep. of Korea', 'Brazil',\n",
       "       'United Arab Emirates', 'Spain', 'United States of America',\n",
       "       'Namibia', 'Netherlands', 'China', 'Israel', 'Barbados', 'Canada',\n",
       "       'Germany', 'Indonesia', 'Ireland', 'Argentina', 'Cuba', 'Italy',\n",
       "       'Switzerland', 'Australia', 'Bulgaria', 'Paraguay', 'Guatemala',\n",
       "       'Austria', 'Dominican Rep.', 'Bolivia', 'Uruguay', 'Estonia',\n",
       "       'Russian Federation', 'Areas, nes', 'Latvia', 'New Zealand',\n",
       "       'Papua New Guinea', 'Thailand', 'Samoa', 'Fiji', 'Christmas Isds',\n",
       "       'Lebanon', 'Nauru', 'Japan', 'French Polynesia', 'Singapore',\n",
       "       'Brunei Darussalam', 'Kiribati', 'Hungary', 'Poland', 'Sweden',\n",
       "       'Peru', 'Ukraine', 'China, Hong Kong SAR', 'Czech Rep.',\n",
       "       'Saudi Arabia', 'Turkey', 'Antigua and Barbuda', 'Bahamas',\n",
       "       'Br. Virgin Isds', 'Dominica', 'Grenada', 'Saint Kitts and Nevis',\n",
       "       'Saint Lucia', 'Saint Vincent and the Grenadines', 'Cayman Isds',\n",
       "       'Anguilla', 'Finland', 'Luxembourg', 'Morocco', 'Slovakia',\n",
       "       'Greece', 'Other Asia, nes', 'Norway', 'Slovenia', 'Lithuania',\n",
       "       'Romania', 'Malawi', 'Nigeria', 'Panama', 'Honduras', 'Armenia',\n",
       "       'Guinea', 'Georgia', 'Viet Nam', 'Ghana', 'Bermuda', 'Sri Lanka',\n",
       "       'Zimbabwe', 'Kenya', 'Kazakhstan', 'Jamaica', 'Jordan', 'Oman',\n",
       "       'Nepal', 'Pakistan', 'Niger', 'Philippines', 'Qatar', 'Rwanda',\n",
       "       'Kyrgyzstan', \"Lao People's Dem. Rep.\", 'Senegal', 'Madagascar',\n",
       "       'Malaysia', 'Mali', 'Sudan', 'Tunisia', 'Togo',\n",
       "       'Turks and Caicos Isds', 'Uganda', 'Egypt', 'Burkina Faso',\n",
       "       'Yemen', 'Zambia', 'Afghanistan', 'Algeria', 'Bahrain',\n",
       "       'Bangladesh', 'Cameroon', 'Central African Rep.', 'Chile',\n",
       "       'Colombia', 'Congo', 'Ecuador', 'Cyprus', 'Swaziland', 'Eritrea',\n",
       "       'Dem.Rep. of the Congo', 'Uzbekistan', 'Malta', 'Iraq', 'Kuwait',\n",
       "       'Mozambique', 'Cambodia', 'Gabon', 'Mauritania', 'Mexico',\n",
       "       'Mongolia', 'Mauritius', 'Gambia', 'Guyana', 'Haiti',\n",
       "       \"Côte d'Ivoire\", 'Sierra Leone', 'Tajikistan', 'Djibouti', 'Iran',\n",
       "       'Libya', 'Liberia', 'Nicaragua', 'Sao Tome and Principe',\n",
       "       'United Rep. of Tanzania', 'Croatia', 'Albania', 'Ethiopia',\n",
       "       'El Salvador', 'Rep. of Moldova', 'Myanmar', 'Burundi', 'Belarus',\n",
       "       'Sint Maarten (Dutch part)', 'Benin', 'Guinea-Bissau', 'Angola',\n",
       "       'Curaçao', 'Solomon Isds', 'Botswana', 'Turkmenistan', 'Syria',\n",
       "       'Trinidad and Tobago', 'South Sudan', 'Seychelles', 'Lesotho',\n",
       "       'Costa Rica', 'Azerbaijan', 'Vanuatu', 'Aruba', 'Suriname',\n",
       "       'Bhutan', 'Serbia', 'TFYR of Macedonia', 'Gibraltar',\n",
       "       'Bosnia Herzegovina', 'Timor-Leste', 'Chad', 'Comoros',\n",
       "       'Montenegro', 'China, Macao SAR', 'Greenland', 'Faeroe Isds',\n",
       "       'Iceland', 'Venezuela', 'Andorra', 'New Caledonia', 'Belize',\n",
       "       'Wallis and Futuna Isds', 'Saint Pierre and Miquelon',\n",
       "       'State of Palestine', 'Bunkers', 'Somalia', 'Maldives', 'Palau',\n",
       "       'FS Micronesia', 'Equatorial Guinea', 'Tonga', 'Cabo Verde',\n",
       "       \"Dem. People's Rep. of Korea\", 'Other Europe, nes', 'Niue',\n",
       "       'Cook Isds', 'Montserrat', 'Tokelau', 'Special Categories',\n",
       "       'Holy See (Vatican City State)', 'San Marino', 'Free Zones',\n",
       "       'Marshall Isds'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Partner.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can observe that we have a node called 'World' but we would like to  analyze the trade relationships between specific countries. Thus we will exclude from the analysis the cases where the reporter or partner is 'World'. Finally, **Period** will be the column that identifies the specific datetime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Partner != 'World']\n",
    "\n",
    "df['Period'] = pd.to_datetime(df['Period'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except the nodes of our analysis which will correspond to countries, the other main features of interest are the **Netweight** of the export/import in kilograms as well as the **Trade Value in US dollars($)**.\n",
    "\n",
    "Now we are in a position that we can start doing some data visualization to get a better understanding of our dataset. Therefore,l ets find the top countries that import/export vaccines in terms of US dollars($)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the top-n number of countries that we want to plot for\n",
    "topn = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point its necessary to introduce two functions for our EDA analysis. One function is being used in order to calculate the statistics of interest, while the second one is to plot the results. Both of these functions our packaged in *Functions* as we mentioned above, but as they mighe be interesting we are also going to include them into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAggStatistics(df: pd.core.frame.DataFrame, feature: str,\n",
    "                     kind: str) -> pd.core.frame.DataFrame:\n",
    "    '''\n",
    "    Given a dataframe and a feature column (numerical), identify the top\n",
    "    importers/exporters.\n",
    "    \n",
    "    Args:\n",
    "    ----\n",
    "        df: DataFrame that contains the data and the required features.\n",
    "        feature: Numerical feature to aggregate (e.g. 'Trade Value (US$)', 'Netweight (kg)')\n",
    "        kind: 'Imports', 'Exports'\n",
    "    Returns:\n",
    "    -------\n",
    "        df_sorted: Sorted dataframe that contains the aggregated values.\n",
    "    '''\n",
    "    df = df.loc[df['Trade Flow'] == kind, [feature,\n",
    "                'Reporter']].groupby(['Reporter']).agg(['sum']).reset_index()\n",
    "\n",
    "    df_sorted = df.sort_values(by=(feature,'sum'), ascending=False)\n",
    "    \n",
    "    return df_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
